{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets as dsets\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchvision.models.resnet as resnet\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import visdom\n",
    "import math\n",
    "import vgg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_tracker(loss_plot, loss_value, num):\n",
    "    vis.line(X=np.stack(np.arange(num, num+1)),\n",
    "             Y=np.stack([loss_value]),\n",
    "             win=loss_plot,\n",
    "             update='append'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (torch.cuda.is_available() == 1):\n",
    "    print(\"cuda is available\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    #transforms.Resize(256),\n",
    "    transforms.RandomCrop(56),\n",
    "    transforms.ToTensor(),]\n",
    "    #transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train = dsets.ImageFolder(root='./tiny-imagenet-200/train',transform=transform)\n",
    "    print(\"Dataset is alreay downlaoded\")\n",
    "except:\n",
    "    !./download.sh\n",
    "    train = dsets.ImageFolder(root='./tiny-imagenet-200/train',transform=transform)\n",
    "    \n",
    "        \n",
    "validation = dsets.ImageFolder(root='./tiny-imagenet-200/val',transform=transform)\n",
    "test = dsets.ImageFolder(root='./tiny-imagenet-200/test',transform=transform)\n",
    "\n",
    "print(train)\n",
    "print(validation)\n",
    "print(test)\n",
    "\n",
    "\n",
    "check_img=train.__getitem__(0)\n",
    "ToPIL=transforms.ToPILImage()\n",
    "check_img = ToPIL(check_img[0])\n",
    "print(check_img)\n",
    "\n",
    "imshow(check_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=data.DataLoader(train, batch_size=256, shuffle=True, num_workers=2)\n",
    "var_loader=data.DataLoader(validation, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader=data.DataLoader(test, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicBlock = resnet.BasicBlock\n",
    "Bottleneck = resnet.Bottleneck\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=1, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = ResNet(BasicBlock, [2,2,2,2])\n",
    "CNN=CNN.to(device)\n",
    "#print(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.Tensor(3,3,56,56).to(device)\n",
    "\n",
    "out = CNN(test_input)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(CNN.parameters(),lr=0.01,momentum=0.9)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer,step_size=2,gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = vis.line(Y=torch.Tensor(1).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "print(\"length of train_loader : {}\".format(len(train_loader)))\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    check_loss = 0.0\n",
    "    lr_sche.step()\n",
    "    for num, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = CNN(inputs)\n",
    "        loss = loss_function(out, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        check_loss += loss.item()\n",
    "        \n",
    "        if (num % 30 == 1) and (num != 1):\n",
    "            check_loss = check_loss/30\n",
    "            print(\"loss : {}\".format(check_loss))\n",
    "            plt_tracker(loss_plot,(check_loss), epoch *len(train_loader) + num)\n",
    "            check_loss = 0  \n",
    "        \n",
    "        if num % len(train_loader) == (len(train_loader) - 1):\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, num + 1, running_loss / len(train_loader)))\n",
    "            running_loss = 0.0\n",
    "            check_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNN.state_dict(),\"./model/tiny_imagenet_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_CNN = ResNet(BasicBlock, [2,2,2,2])\n",
    "load_CNN=CNN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_CNN.load_state_dict(torch.load('./model/tiny_imagenet_resnet.pth',map_location = device))\n",
    "load_CNN = load_CNN.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_CNN.conv1.weight[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CNN.conv1.weight.data[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_CNN == CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
